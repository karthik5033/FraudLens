{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBaqN3GrTW8T",
        "outputId": "945ec8c1-c3b5-45c1-e420-fcedae14f1b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All dependencies installed and ready!\n",
            "============================================================\n",
            "UPI-GUARDIAN: MEMBER 3 & 4 PIPELINE (Colab)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "MEMBER 3: GNN FRAUD GRAPH MODEL\n",
            "============================================================\n",
            "âœ… Loaded 604 edges from dataset_graph.csv\n",
            "âœ… Graph created: 290 nodes, 604 edges\n",
            "\n",
            "ðŸ”„ Training GNN...\n",
            "  Epoch 10/50, Loss: 0.3486\n",
            "  Epoch 20/50, Loss: 0.1427\n",
            "  Epoch 30/50, Loss: 0.0503\n",
            "  Epoch 40/50, Loss: 0.0210\n",
            "  Epoch 50/50, Loss: 0.0113\n",
            "âœ… GNN training complete!\n",
            "âœ… Detected 158 high-risk nodes\n",
            "\n",
            "ðŸ“Š Top 10 High-Risk Nodes:\n",
            "  device:android_49: 1.000\n",
            "  device:android_14: 1.000\n",
            "  device:android_4: 1.000\n",
            "  phone:9507943839: 1.000\n",
            "  device:android_6: 1.000\n",
            "  device:ios_16: 1.000\n",
            "  device:android_8: 1.000\n",
            "  phone:9914763202: 1.000\n",
            "  phone:9734036506: 1.000\n",
            "  phone:9485451171: 1.000\n",
            "âœ… GNN model saved to models/gnn/gnn_model.pt\n",
            "\n",
            "============================================================\n",
            "MEMBER 4A: BEHAVIORAL ANOMALY MODEL\n",
            "============================================================\n",
            "âœ… Loaded 3000 behavioral sessions\n",
            "  Features: ['total_time_seconds', 'tab_switches', 'scroll_loops', 'hover_time_ms', 'avg_click_interval_ms', 'click_repetition_count', 'keystroke_latency_ms', 'window_focus_events']\n",
            "  Label distribution: {0: 2100, 1: 900}\n",
            "âœ… Behavioral anomaly model trained!\n",
            "  Contamination: 0.3\n",
            "  Features: 8\n",
            "\n",
            "ðŸ“Š Sample Risk Predictions (first 5 sessions):\n",
            "  Session 0: 0.729 ðŸ”´ HIGH RISK\n",
            "  Session 1: 0.764 ðŸ”´ HIGH RISK\n",
            "  Session 2: 0.739 ðŸ”´ HIGH RISK\n",
            "  Session 3: 0.731 ðŸ”´ HIGH RISK\n",
            "  Session 4: 0.759 ðŸ”´ HIGH RISK\n",
            "âœ… Behavioral model saved to models/behavior/behavior_model.pkl\n",
            "\n",
            "============================================================\n",
            "MEMBER 4B: FUSION ENGINE\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š Example Fusion Results (Simulated Inputs):\n",
            "\n",
            "  High Risk (Refund Scam):\n",
            "    Final Score: 0.818\n",
            "    Fraud Type: verification_fraud\n",
            "    Confidence: 0.722\n",
            "    Explanation: ðŸ”´ HIGH RISK - Scam language detected, suspicious transaction pattern, linked to fraud network, unusual user behavior\n",
            "\n",
            "  Low Risk (Safe):\n",
            "    Final Score: 0.17\n",
            "    Fraud Type: refund_scam\n",
            "    Confidence: 0.4\n",
            "    Explanation: ðŸŸ¢ LOW RISK - All signals normal\n",
            "\n",
            "  Medium Risk (KYC Scam):\n",
            "    Final Score: 0.527\n",
            "    Fraud Type: kyc_scam\n",
            "    Confidence: 0.667\n",
            "    Explanation: ðŸŸ  MEDIUM RISK - All signals normal\n",
            "âœ… Fusion engine config saved to models/fusion_engine.json\n",
            "\n",
            "============================================================\n",
            "âœ… PIPELINE COMPLETE!\n",
            "============================================================\n",
            "\n",
            "ðŸ“¦ Saved Artifacts:\n",
            "  - models/gnn/gnn_model.pt\n",
            "  - models/behavior/behavior_model.pkl\n",
            "  - models/fusion_engine.json\n",
            "\n",
            " Ready for integration with Member 1 & 2 models!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GraphSAGE, GATConv\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"âœ… All dependencies installed and ready!\")\n",
        "\n",
        "# ============================================================\n",
        "# PART 1: GNN FRAUD GRAPH MODEL (Member 3)\n",
        "# ============================================================\n",
        "\n",
        "class FraudGraphSAGE(nn.Module):\n",
        "    \"\"\"GraphSAGE model for fraud detection in UPI networks\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2):\n",
        "        super(FraudGraphSAGE, self).__init__()\n",
        "        self.graphsage = GraphSAGE(\n",
        "            in_channels=in_channels,\n",
        "            hidden_channels=hidden_channels,\n",
        "            num_layers=num_layers,\n",
        "            out_channels=out_channels\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out = self.graphsage(x, edge_index)\n",
        "        return torch.sigmoid(out)  # Probability output\n",
        "\n",
        "\n",
        "class GNNFraudDetector:\n",
        "    \"\"\"Complete GNN pipeline for fraud graph analysis\"\"\"\n",
        "\n",
        "    def __init__(self, dataset_path='dataset_graph.csv'):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.model = None\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.node_mapping = {}\n",
        "        self.edge_mapping = {}\n",
        "        self.fraud_clusters = {}\n",
        "\n",
        "    def load_graph_data(self):\n",
        "        \"\"\"Load and preprocess graph dataset\"\"\"\n",
        "        df = pd.read_csv(self.dataset_path)\n",
        "        print(f\"âœ… Loaded {len(df)} edges from {self.dataset_path}\")\n",
        "\n",
        "        # Create node mappings\n",
        "        all_nodes = set(df['src_id'].unique()) | set(df['dst_id'].unique())\n",
        "        self.node_mapping = {node: idx for idx, node in enumerate(sorted(all_nodes))}\n",
        "        self.reverse_node_mapping = {idx: node for node, idx in self.node_mapping.items()}\n",
        "        num_nodes = len(self.node_mapping)\n",
        "\n",
        "        edge_index_list = []\n",
        "        node_labels = torch.zeros(num_nodes, dtype=torch.float) # Target labels for nodes\n",
        "\n",
        "        # For node features (average incident edge risk)\n",
        "        node_incident_risk_sum = torch.zeros(num_nodes, dtype=torch.float)\n",
        "        node_incident_edge_count = torch.zeros(num_nodes, dtype=torch.float)\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            src_idx = self.node_mapping[row['src_id']]\n",
        "            dst_idx = self.node_mapping[row['dst_id']] # Corrected: previously typo `row['src_id']`\n",
        "            edge_index_list.append([src_idx, dst_idx])\n",
        "            risk_hint = row['risk_hint']\n",
        "\n",
        "            # Assign node labels (target): a node is risky if any of its incident edges are risky\n",
        "            node_labels[src_idx] = max(node_labels[src_idx], risk_hint)\n",
        "            node_labels[dst_idx] = max(node_labels[dst_idx], risk_hint)\n",
        "\n",
        "            # Accumulate risk for node feature calculation\n",
        "            node_incident_risk_sum[src_idx] += risk_hint\n",
        "            node_incident_edge_count[src_idx] += 1\n",
        "            node_incident_risk_sum[dst_idx] += risk_hint\n",
        "            node_incident_edge_count[dst_idx] += 1\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "\n",
        "        # Node features (in-degree, out-degree, average incident edge risk)\n",
        "        x = torch.zeros(num_nodes, 3)\n",
        "\n",
        "        # Calculate in-degree and out-degree\n",
        "        for src, dst in edge_index.t().tolist(): # Transpose back to iterate (src, dst) pairs\n",
        "            x[dst, 0] += 1  # in-degree\n",
        "            x[src, 1] += 1  # out-degree\n",
        "\n",
        "        # Feature 3: Average incident edge risk\n",
        "        # Avoid division by zero\n",
        "        avg_incident_risk = torch.zeros(num_nodes, dtype=torch.float)\n",
        "        valid_indices = node_incident_edge_count > 0\n",
        "        avg_incident_risk[valid_indices] = node_incident_risk_sum[valid_indices] / node_incident_edge_count[valid_indices]\n",
        "        x[:, 2] = avg_incident_risk\n",
        "\n",
        "        # Create the Data object with node-level target labels\n",
        "        self.graph_data = Data(x=x, edge_index=edge_index, y=node_labels.view(-1, 1))\n",
        "        print(f\"âœ… Graph created: {self.graph_data.num_nodes} nodes, {self.graph_data.num_edges} edges\")\n",
        "        return self.graph_data\n",
        "\n",
        "    def train(self, epochs=50, hidden_channels=64, learning_rate=0.01):\n",
        "        \"\"\"Train GNN model\"\"\"\n",
        "        self.model = FraudGraphSAGE(\n",
        "            in_channels=self.graph_data.x.shape[1],\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=1,\n",
        "            num_layers=2\n",
        "        ).to(self.device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        # Move data to device\n",
        "        x = self.graph_data.x.to(self.device)\n",
        "        edge_index = self.graph_data.edge_index.to(self.device)\n",
        "        y = self.graph_data.y.to(self.device) # .view(-1, 1) is already done in Data creation\n",
        "\n",
        "        print(\"\\nðŸ”„ Training GNN...\")\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            out = self.model(x, edge_index)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"  Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        print(\"âœ… GNN training complete!\")\n",
        "        return self.model\n",
        "\n",
        "    def get_node_risk_scores(self):\n",
        "        \"\"\"Get risk scores for all nodes\"\"\"\n",
        "        self.model.eval()\n",
        "        x = self.graph_data.x.to(self.device)\n",
        "        edge_index = self.graph_data.edge_index.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            scores = self.model(x, edge_index).cpu().numpy()\n",
        "\n",
        "        node_risks = {self.reverse_node_mapping[i]: scores[i][0]\n",
        "                      for i in range(len(scores))}\n",
        "        return node_risks\n",
        "\n",
        "    def detect_fraud_clusters(self, threshold=0.5):\n",
        "        \"\"\"Detect connected fraud clusters\"\"\"\n",
        "        node_risks = self.get_node_risk_scores()\n",
        "        high_risk_nodes = {k: v for k, v in node_risks.items() if v > threshold}\n",
        "\n",
        "        print(f\"âœ… Detected {len(high_risk_nodes)} high-risk nodes\")\n",
        "        return high_risk_nodes\n",
        "\n",
        "    def save_model(self, save_path='models/gnn/gnn_model.pt'):\n",
        "        \"\"\"Save trained model\"\"\"\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        torch.save(\n",
        "            {\n",
        "                'model_state': self.model.state_dict(),\n",
        "                'node_mapping': self.node_mapping,\n",
        "                'reverse_node_mapping': self.reverse_node_mapping\n",
        "            }, save_path)\n",
        "        print(f\"âœ… GNN model saved to {save_path}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PART 2: BEHAVIORAL ANOMALY MODEL (Member 4)\n",
        "# ============================================================\n",
        "\n",
        "class BehavioralAnomalyDetector:\n",
        "    \"\"\"Isolation Forest for behavioral anomaly detection\"\"\"\n",
        "\n",
        "    def __init__(self, dataset_path='dataset_behavior.csv', contamination=0.3):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.contamination = contamination\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_names = None\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load behavioral dataset\"\"\"\n",
        "        df = pd.read_csv(self.dataset_path)\n",
        "        self.feature_names = [col for col in df.columns\n",
        "                             if col not in ['session_id', 'label']]\n",
        "        X = df[self.feature_names]\n",
        "        y = df['label']\n",
        "\n",
        "        print(f\"âœ… Loaded {len(df)} behavioral sessions\")\n",
        "        print(f\"  Features: {self.feature_names}\")\n",
        "        print(f\"  Label distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def train(self, X):\n",
        "        \"\"\"Train Isolation Forest\"\"\"\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Train model\n",
        "        self.model = IsolationForest(\n",
        "            contamination=self.contamination,\n",
        "            random_state=42,\n",
        "            n_estimators=100\n",
        "        )\n",
        "        self.model.fit(X_scaled)\n",
        "\n",
        "        print(f\"âœ… Behavioral anomaly model trained!\")\n",
        "        print(f\"  Contamination: {self.contamination}\")\n",
        "        print(f\"  Features: {len(self.feature_names)}\")\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def predict_risk(self, X):\n",
        "        \"\"\"Predict anomaly scores (0-1, higher = more anomalous)\"\"\"\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        # Get anomaly scores (-1 to 1, convert to 0-1)\n",
        "        scores = self.model.score_samples(X_scaled)\n",
        "        normalized_scores = (1 - (scores + 1) / 2)  # Normalize to 0-1\n",
        "\n",
        "        return normalized_scores\n",
        "\n",
        "    def save_model(self, save_path='models/behavior/behavior_model.pkl'):\n",
        "        \"\"\"Save trained model\"\"\"\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        joblib.dump(\n",
        "            {\n",
        "                'model': self.model,\n",
        "                'scaler': self.scaler,\n",
        "                'feature_names': self.feature_names\n",
        "            }, save_path)\n",
        "        print(f\"âœ… Behavioral model saved to {save_path}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PART 3: FUSION ENGINE (Member 4)\n",
        "# ============================================================\n",
        "\n",
        "class FraudFusionEngine:\n",
        "    \"\"\"Fuses all 4 model outputs into final fraud score\"\"\"\n",
        "\n",
        "    # Weights for fusion (customizable)\n",
        "    WEIGHTS = {\n",
        "        'nlp': 0.30,\n",
        "        'transaction': 0.35,\n",
        "        'graph': 0.20,\n",
        "        'behavior': 0.15\n",
        "    }\n",
        "\n",
        "    FRAUD_TYPES = {\n",
        "        'refund_scam': 'Refund/UPI reversal scam',\n",
        "        'kyc_scam': 'Fake KYC/identity verification',\n",
        "        'impersonation': 'Impersonation (delivery/bank/support)',\n",
        "        'verification_fraud': 'Fake verification transaction',\n",
        "        'safe': 'Safe transaction'\n",
        "    }\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_final_score(nlp_risk, transaction_risk, graph_risk, behavior_risk):\n",
        "        \"\"\"\n",
        "        Compute final fraud score using weighted fusion\n",
        "\n",
        "        Args:\n",
        "            nlp_risk (float): 0-1, scam language likelihood\n",
        "            transaction_risk (float): 0-1, suspicious transaction pattern\n",
        "            graph_risk (float): 0-1, linked to fraud network\n",
        "            behavior_risk (float): 0-1, user behavior anomaly\n",
        "\n",
        "        Returns:\n",
        "            dict: final_score, fraud_type, confidence, explanation\n",
        "        \"\"\"\n",
        "        final_score = (\n",
        "            FraudFusionEngine.WEIGHTS['nlp'] * nlp_risk +\n",
        "            FraudFusionEngine.WEIGHTS['transaction'] * transaction_risk +\n",
        "            FraudFusionEngine.WEIGHTS['graph'] * graph_risk +\n",
        "            FraudFusionEngine.WEIGHTS['behavior'] * behavior_risk\n",
        "        )\n",
        "\n",
        "        # Determine fraud type (highest contributing risk)\n",
        "        risks = {\n",
        "            'nlp': nlp_risk,\n",
        "            'transaction': transaction_risk,\n",
        "            'graph': graph_risk,\n",
        "            'behavior': behavior_risk\n",
        "        }\n",
        "        dominant_risk = max(risks, key=risks.get)\n",
        "\n",
        "        # Map to fraud type\n",
        "        fraud_type_map = {\n",
        "            'nlp': 'refund_scam' if nlp_risk > 0.7 else 'kyc_scam',\n",
        "            'transaction': 'verification_fraud',\n",
        "            'graph': 'impersonation',\n",
        "            'behavior': 'refund_scam'\n",
        "        }\n",
        "        predicted_type = fraud_type_map.get(dominant_risk, 'safe')\n",
        "\n",
        "        # Confidence based on consensus\n",
        "        max_score = max(nlp_risk, transaction_risk, graph_risk, behavior_risk)\n",
        "        min_score = min(nlp_risk, transaction_risk, graph_risk, behavior_risk)\n",
        "        confidence = 1 - (abs(max_score - min_score) / (max_score + 1e-8))\n",
        "\n",
        "        # Human-readable explanation\n",
        "        explanation = FraudFusionEngine.generate_explanation(\n",
        "            final_score, nlp_risk, transaction_risk, graph_risk, behavior_risk\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'final_score': round(final_score, 3),\n",
        "            'fraud_type': predicted_type,\n",
        "            'confidence': round(confidence, 3),\n",
        "            'explanation': explanation,\n",
        "            'component_scores': {\n",
        "                'nlp_risk': round(nlp_risk, 3),\n",
        "                'transaction_risk': round(transaction_risk, 3),\n",
        "                'graph_risk': round(graph_risk, 3),\n",
        "                'behavior_risk': round(behavior_risk, 3)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_explanation(final_score, nlp_risk, transaction_risk, graph_risk, behavior_risk):\n",
        "        \"\"\"Generate human-readable explanation for fraud score\"\"\"\n",
        "        if final_score > 0.7:\n",
        "            severity = \"ðŸ”´ HIGH RISK\"\n",
        "        elif final_score > 0.4:\n",
        "            severity = \"ðŸŸ  MEDIUM RISK\"\n",
        "        else:\n",
        "            severity = \"ðŸŸ¢ LOW RISK\"\n",
        "\n",
        "        reasons = []\n",
        "        if nlp_risk > 0.6:\n",
        "            reasons.append(\"scam language detected\")\n",
        "        if transaction_risk > 0.6:\n",
        "            reasons.append(\"suspicious transaction pattern\")\n",
        "        if graph_risk > 0.6:\n",
        "            reasons.append(\"linked to fraud network\")\n",
        "        if behavior_risk > 0.6:\n",
        "            reasons.append(\"unusual user behavior\")\n",
        "\n",
        "        reason_str = \", \".join(reasons) if reasons else \"all signals normal\"\n",
        "\n",
        "        return f\"{severity} - {reason_str.capitalize()}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def save_fusion_config(save_path='models/fusion_engine.json'):\n",
        "        \"\"\"Save fusion engine configuration\"\"\"\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        config = {\n",
        "            'weights': FraudFusionEngine.WEIGHTS,\n",
        "            'fraud_types': FraudFusionEngine.FRAUD_TYPES,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "        with open(save_path, 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "        print(f\"âœ… Fusion engine config saved to {save_path}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# EXECUTION PIPELINE\n",
        "# ============================================================\n",
        "\n",
        "def run_full_pipeline():\n",
        "    \"\"\"Execute complete Member 3 & 4 pipeline\"\"\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"UPI-GUARDIAN: MEMBER 3 & 4 PIPELINE (Colab)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # ========== MEMBER 3: GNN MODEL ==========\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MEMBER 3: GNN FRAUD GRAPH MODEL\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    gnn_detector = GNNFraudDetector('dataset_graph.csv')\n",
        "    gnn_detector.load_graph_data()\n",
        "    gnn_detector.train(epochs=50, hidden_channels=64)\n",
        "\n",
        "    # Get fraud clusters\n",
        "    high_risk_nodes = gnn_detector.detect_fraud_clusters(threshold=0.5)\n",
        "    print(f\"\\nðŸ“Š Top 10 High-Risk Nodes:\")\n",
        "    for node, score in sorted(high_risk_nodes.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "        print(f\"  {node}: {score:.3f}\")\n",
        "\n",
        "    # Save GNN model\n",
        "    gnn_detector.save_model('models/gnn/gnn_model.pt')\n",
        "\n",
        "    # ========== MEMBER 4A: BEHAVIORAL MODEL ==========\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MEMBER 4A: BEHAVIORAL ANOMALY MODEL\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    behavior_detector = BehavioralAnomalyDetector('dataset_behavior.csv', contamination=0.3)\n",
        "    X, y = behavior_detector.load_data()\n",
        "    behavior_detector.train(X)\n",
        "\n",
        "    # Get sample predictions\n",
        "    sample_risks = behavior_detector.predict_risk(X[:5])\n",
        "    print(f\"\\nðŸ“Š Sample Risk Predictions (first 5 sessions):\")\n",
        "    for i, risk in enumerate(sample_risks):\n",
        "        print(f\"  Session {i}: {risk:.3f} {'ðŸ”´ HIGH RISK' if risk > 0.6 else 'ðŸŸ¢ LOW RISK'}\")\n",
        "\n",
        "    # Save behavioral model\n",
        "    behavior_detector.save_model('models/behavior/behavior_model.pkl')\n",
        "\n",
        "    # ========== MEMBER 4B: FUSION ENGINE ==========\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MEMBER 4B: FUSION ENGINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Example: Simulate predictions from all 4 members\n",
        "    print(\"\\nðŸ“Š Example Fusion Results (Simulated Inputs):\")\n",
        "\n",
        "    test_cases = [\n",
        "        {'nlp': 0.85, 'transaction': 0.90, 'graph': 0.75, 'behavior': 0.65, 'name': 'High Risk (Refund Scam)'},\n",
        "        {'nlp': 0.20, 'transaction': 0.15, 'graph': 0.10, 'behavior': 0.25, 'name': 'Low Risk (Safe)'},\n",
        "        {'nlp': 0.60, 'transaction': 0.55, 'graph': 0.40, 'behavior': 0.50, 'name': 'Medium Risk (KYC Scam)'}\n",
        "    ]\n",
        "\n",
        "    for test in test_cases:\n",
        "        result = FraudFusionEngine.compute_final_score(\n",
        "            test['nlp'], test['transaction'], test['graph'], test['behavior']\n",
        "        )\n",
        "        print(f\"\\n  {test['name']}:\")\n",
        "        print(f\"    Final Score: {result['final_score']}\")\n",
        "        print(f\"    Fraud Type: {result['fraud_type']}\")\n",
        "        print(f\"    Confidence: {result['confidence']}\")\n",
        "        print(f\"    Explanation: {result['explanation']}\")\n",
        "\n",
        "    # Save fusion config\n",
        "    FraudFusionEngine.save_fusion_config('models/fusion_engine.json')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"âœ… PIPELINE COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nðŸ“¦ Saved Artifacts:\")\n",
        "    print(\"  - models/gnn/gnn_model.pt\")\n",
        "    print(\"  - models/behavior/behavior_model.pkl\")\n",
        "    print(\"  - models/fusion_engine.json\")\n",
        "    print(\"\\n Ready for integration with Member 1 & 2 models!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_full_pipeline()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "krQDd9ygTiyT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}